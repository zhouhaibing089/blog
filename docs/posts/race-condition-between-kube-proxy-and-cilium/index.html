<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Race condition between kube-proxy and cilium | Blog</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.111.3">
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.4fc0b62e4b82c997bb0041217cd6b979.css" rel="stylesheet">
    

    
      <link rel="stylesheet" href="/css/custom.css">
    
      <link rel="stylesheet" href="/css/syntax.css">
    

    
      

    

    
    
    <meta property="og:title" content="Race condition between kube-proxy and cilium" />
<meta property="og:description" content="This is an investigation story where all pods on one host lost connectivity to external service. It looks like something below:
$ nsenter --net=/proc/29080/ns/net curl docs.cilium.io -v &gt; GET / HTTP/1.1 &gt; Host: docs.cilium.io &gt; User-Agent: curl/7.79.1 &gt; Accept: */* &gt; Here 29080 is the pid of some pod process, and it appeared that TCP connection has been established, but somehow it couldn&rsquo;t receive any response.
About the cluster The cluster was set up like something below:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.zhouhaibing.com/posts/race-condition-between-kube-proxy-and-cilium/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-27T16:00:00-07:00" />
<meta property="article:modified_time" content="2023-05-27T16:00:00-07:00" />
<meta itemprop="name" content="Race condition between kube-proxy and cilium">
<meta itemprop="description" content="This is an investigation story where all pods on one host lost connectivity to external service. It looks like something below:
$ nsenter --net=/proc/29080/ns/net curl docs.cilium.io -v &gt; GET / HTTP/1.1 &gt; Host: docs.cilium.io &gt; User-Agent: curl/7.79.1 &gt; Accept: */* &gt; Here 29080 is the pid of some pod process, and it appeared that TCP connection has been established, but somehow it couldn&rsquo;t receive any response.
About the cluster The cluster was set up like something below:"><meta itemprop="datePublished" content="2023-05-27T16:00:00-07:00" />
<meta itemprop="dateModified" content="2023-05-27T16:00:00-07:00" />
<meta itemprop="wordCount" content="1534">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Race condition between kube-proxy and cilium"/>
<meta name="twitter:description" content="This is an investigation story where all pods on one host lost connectivity to external service. It looks like something below:
$ nsenter --net=/proc/29080/ns/net curl docs.cilium.io -v &gt; GET / HTTP/1.1 &gt; Host: docs.cilium.io &gt; User-Agent: curl/7.79.1 &gt; Accept: */* &gt; Here 29080 is the pid of some pod process, and it appeared that TCP connection has been established, but somehow it couldn&rsquo;t receive any response.
About the cluster The cluster was set up like something below:"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Blog
      
    </a>
    <div class="flex-l items-center">
      

      
      















    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://blog.zhouhaibing.com/posts/race-condition-between-kube-proxy-and-cilium/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://blog.zhouhaibing.com/posts/race-condition-between-kube-proxy-and-cilium/&amp;text=Race%20condition%20between%20kube-proxy%20and%20cilium" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://blog.zhouhaibing.com/posts/race-condition-between-kube-proxy-and-cilium/&amp;title=Race%20condition%20between%20kube-proxy%20and%20cilium" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Race condition between kube-proxy and cilium</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-05-27T16:00:00-07:00">May 27, 2023</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>This is an investigation story where all pods on one host lost connectivity to
external service. It looks like something below:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> nsenter --net<span class="o">=</span>/proc/29080/ns/net curl docs.cilium.io -v
</span></span><span class="line"><span class="cl"><span class="gp">&gt;</span> GET / HTTP/1.1
</span></span><span class="line"><span class="cl"><span class="gp">&gt;</span> Host: docs.cilium.io
</span></span><span class="line"><span class="cl"><span class="gp">&gt;</span> User-Agent: curl/7.79.1
</span></span><span class="line"><span class="cl"><span class="gp">&gt;</span> Accept: */*
</span></span><span class="line"><span class="cl"><span class="gp">&gt;</span>
</span></span></code></pre></div><p>Here <strong>29080</strong> is the pid of some pod process, and it appeared that TCP
connection has been established, but somehow it couldn&rsquo;t receive any response.</p>
<h2 id="about-the-cluster">About the cluster</h2>
<p>The cluster was set up like something below:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> minikube start --driver<span class="o">=</span>virtualbox --cpus<span class="o">=</span><span class="m">4</span> --memory<span class="o">=</span>8g --network-plugin<span class="o">=</span>cni <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="go">    --cni=false --nodes=3
</span></span></span></code></pre></div><p>and then cilium was installed with:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> cilium install --kube-proxy-replacement<span class="o">=</span>probe <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="go">    --helm-set ipam.operator.clusterPoolIPv4PodCIDR=172.16.0.0/16 \
</span></span></span><span class="line"><span class="cl"><span class="go">    --helm-set bpf.masquerade=true \
</span></span></span><span class="line"><span class="cl"><span class="go">    --version=v1.11.17
</span></span></span></code></pre></div><p>In short, this is a cluster created with minikube, and then cilium was
installed as the CNI plugin, and as kube-proxy replacement whenever possible.</p>
<h2 id="about-the-pod-network">About the pod network</h2>
<p>Below is a basic representation of the network setup for the pod which had
connectivity issues:</p>
<p><img src="/images/kube-proxy-cilium.svg" alt="pod-node-network"></p>
<p>There is a veth pair with one end in pod and the other end in host. It basically
connects the pod network namespace to host network namespace. There is another
veth pair with both ends in host (<code>cilium_net</code> and <code>cilium_host</code>).</p>
<h2 id="tcpdump">tcpdump</h2>
<p>To understand why the pod couldn&rsquo;t receive anything back, we can run <code>tcpdump</code>
to analyze the traffic flow. To start with, we can try pod network namespace
first:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> nsenter --net<span class="o">=</span>/proc/29080/ns/net tcpdump -i any host 104.17.32.82 -nn
</span></span><span class="line"><span class="cl"><span class="go">23:43:46.468314 eth0  Out IP 172.16.0.30.50880 &gt; 104.17.32.82.80: Flags [S], seq 2499115150, win 64860, options [mss 1410,sackOK,TS val 239543031 ecr 0,nop,wscale 7], length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:46.478847 eth0  In  IP 104.17.32.82.80 &gt; 172.16.0.30.50880: Flags [S.], seq 881408001, ack 2499115151, win 65535, options [mss 1460], length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:46.478867 eth0  Out IP 172.16.0.30.50880 &gt; 104.17.32.82.80: Flags [.], ack 1, win 64860, length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:46.478892 eth0  Out IP 172.16.0.30.50880 &gt; 104.17.32.82.80: Flags [P.], seq 1:79, ack 1, win 64860, length 78: HTTP: GET / HTTP/1.1
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:46.693746 eth0  Out IP 172.16.0.30.50880 &gt; 104.17.32.82.80: Flags [P.], seq 1:79, ack 1, win 64860, length 78: HTTP: GET / HTTP/1.1
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:47.117837 eth0  Out IP 172.16.0.30.50880 &gt; 104.17.32.82.80: Flags [P.], seq 1:79, ack 1, win 64860, length 78: HTTP: GET / HTTP/1.1
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:54.143858 eth0  In  IP 104.17.32.82.80 &gt; 172.16.0.30.50880: Flags [S.], seq 881408001, ack 2499115151, win 65535, options [mss 1460], length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:43:54.143877 eth0  Out IP 172.16.0.30.50880 &gt; 104.17.32.82.80: Flags [.], ack 1, win 64860, length 0
</span></span></span></code></pre></div><p>To make it more readable:</p>
<ol>
<li>172.16.0.30.50880 (pod) -&gt; 104.17.32.82.80 (server): SYN</li>
<li>104.17.32.82.80 (server) -&gt; 172.16.0.30.50880 (pod): SYN and ACK</li>
<li>172.16.0.30.50880 (pod) -&gt; 104.17.32.82.80 (server): ACK</li>
<li>172.16.0.30.50880 (pod) -&gt; 104.17.32.82.80 (server): PUSH and ACK</li>
</ol>
<p>Step 4 was retried several times, until there is another SYN and ACK replied
from server. This mostly means that the server didn&rsquo;t see the ACK reply from
step 3, and thus retried step 2, but then what happened to the ACK in step 3?</p>
<p>We can then run the same tcpdump command from host, and see what happened in
host network namespace:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> tcpdump -i any host 104.17.32.82 -nn
</span></span><span class="line"><span class="cl"><span class="go">23:53:50.103850 lxc3055a222b7f1 In  IP 172.16.0.30.50992 &gt; 104.17.32.82.80: Flags [S], seq 2399693262, win 64860, options [mss 1410,sackOK,TS val 240146666 ecr 0,nop,wscale 7], length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:53:50.103919 eth0  Out IP 10.0.2.15.50992 &gt; 104.17.32.82.80: Flags [S], seq 2399693262, win 64860, options [mss 1410,sackOK,TS val 240146666 ecr 0,nop,wscale 7], length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:53:50.115561 eth0  In  IP 104.17.32.82.80 &gt; 10.0.2.15.50992: Flags [S.], seq 958144001, ack 2399693263, win 65535, options [mss 1460], length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:53:50.115586 lxc3055a222b7f1 In  IP 172.16.0.30.50992 &gt; 104.17.32.82.80: Flags [.], ack 958144002, win 64860, length 0
</span></span></span><span class="line"><span class="cl"><span class="go">23:53:50.115677 lxc3055a222b7f1 In  IP 172.16.0.30.50992 &gt; 104.17.32.82.80: Flags [P.], seq 0:78, ack 1, win 64860, length 78: HTTP: GET / HTTP/1.1
</span></span></span></code></pre></div><p>From host perspective, we can observe traffic coming from <code>lxc3055a222b7f1</code>
which is the host end of pod veth pair. Here the first SYN packet actually was
sent out from <code>eth0</code> interface, but none of the other packets were sent out via
<code>eth0</code>. The <code>ACK</code> packet replied by pod clearly was lost somewhere.</p>
<h2 id="iptables">iptables</h2>
<p>Here we can make few guesses:</p>
<ol>
<li>It is more likely dropped by iptables than bpf.</li>
<li>It is more likely related to conntrack iptables rules.</li>
</ol>
<p>The second guess is based on the fact that first SYN packet was sent out without
any issues. To examine this guess, we can find out all the iptables rules which
can drop packets based on conntrack states via:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> iptables -S <span class="p">|</span> grep DROP <span class="p">|</span> grep <span class="s2">&#34;ctstate&#34;</span>
</span></span><span class="line"><span class="cl"><span class="go">-A KUBE-FIREWALL ! -s 127.0.0.0/8 -d 127.0.0.0/8 -m comment --comment &#34;block incoming localnet connections&#34; -m conntrack ! --ctstate RELATED,ESTABLISHED,DNAT -j DROP
</span></span></span><span class="line"><span class="cl"><span class="go">-A KUBE-FORWARD -m conntrack --ctstate INVALID -j DROP
</span></span></span></code></pre></div><p>The first rule doesn&rsquo;t matter because <code>-d 127.0.0.0/8</code> isn&rsquo;t our case, so let&rsquo;s
focus on the second rule.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="go">-A KUBE-FORWARD -m conntrack --ctstate INVALID -j DROP
</span></span></span></code></pre></div><p>This rule says that if <code>ctstate</code> is INVALID, then the packet should be dropped.
We can find the place of this rule fairly straightforward:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> iptables -t filter -nvL KUBE-FORWARD
</span></span><span class="line"><span class="cl"><span class="go">Chain KUBE-FORWARD (1 references)
</span></span></span><span class="line"><span class="cl"><span class="go"> pkts bytes target     prot opt in     out     source               destination
</span></span></span><span class="line"><span class="cl"><span class="go">    5   512 DROP       all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate INVALID
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */ mark match 0x4000/0x4000
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding conntrack rule */ ctstate RELATED,ESTABLISHED
</span></span></span></code></pre></div><p>Here we can inspect the dropped <code>pkts/bytes</code> by running the tests again, and it
isn&rsquo;t difficult to confirm that it is indeed this rule which dropped our
packets.</p>
<p>Starting from here, we have two questions to ask:</p>
<ol>
<li>How does it look like from a good host?</li>
<li>Why the conntrack state is INVALID?</li>
</ol>
<h2 id="compare-with-good-host">Compare with good host</h2>
<p>This is also straightforward. <code>KUBE-FOREWARD</code> chain can only be jumpped from
<code>FORWARD</code> chain, so let&rsquo;s just compare how does it look like in <code>FORWARD</code> chain:</p>
<p>On a bad host:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> iptables -t filter -nvL FORWARD
</span></span><span class="line"><span class="cl"><span class="go">Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)
</span></span></span><span class="line"><span class="cl"><span class="go"> pkts bytes target     prot opt in     out     source               destination
</span></span></span><span class="line"><span class="cl"><span class="go">   11   660 KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
</span></span></span><span class="line"><span class="cl"><span class="go">  169 14804 KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
</span></span></span><span class="line"><span class="cl"><span class="go">   11   660 KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
</span></span></span><span class="line"><span class="cl"><span class="go">   11   660 KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
</span></span></span><span class="line"><span class="cl"><span class="go">   11   660 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">   11   660 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    7   420 CILIUM_FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* cilium-feeder: CILIUM_FORWARD */
</span></span></span></code></pre></div><p>and on a good host:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> iptables -t filter -nvL FORWARD
</span></span><span class="line"><span class="cl"><span class="go">Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)
</span></span></span><span class="line"><span class="cl"><span class="go"> pkts bytes target     prot opt in     out     source               destination
</span></span></span><span class="line"><span class="cl"><span class="go"> 1419  148K CILIUM_FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* cilium-feeder: CILIUM_FORWARD */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0
</span></span></span></code></pre></div><p>The difference here is that <code>CILIUM_FORWARD</code> is matched first. We can see what&rsquo;s
in <code>CILIUM_FORWARD</code> with:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> iptables -t filter -nvL CILIUM_FORWARD
</span></span><span class="line"><span class="cl"><span class="go">Chain CILIUM_FORWARD (1 references)
</span></span></span><span class="line"><span class="cl"><span class="go"> pkts bytes target     prot opt in     out     source               destination
</span></span></span><span class="line"><span class="cl"><span class="go">  642 93820 ACCEPT     all  --  *      cilium_host  0.0.0.0/0            0.0.0.0/0            /* cilium: any-&gt;cluster on cilium_host forward accept */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  cilium_host *       0.0.0.0/0            0.0.0.0/0            /* cilium: cluster-&gt;any on cilium_host forward accept (nodeport) */
</span></span></span><span class="line"><span class="cl"><span class="go">  794 56164 ACCEPT     all  --  lxc+   *       0.0.0.0/0            0.0.0.0/0            /* cilium: cluster-&gt;any on lxc+ forward accept */
</span></span></span><span class="line"><span class="cl"><span class="go">    0     0 ACCEPT     all  --  cilium_net *       0.0.0.0/0            0.0.0.0/0            /* cilium: cluster-&gt;any on cilium_net forward accept (nodeport) */
</span></span></span></code></pre></div><p>Here, the packet is accepted if the packet is sent from <code>lxc+</code>, and thus the
packet won&rsquo;t continue matching with <code>KUBE-FORWARD</code>.</p>
<h2 id="how-did-it-happen">How did it happen</h2>
<p>We can look at the code in kube-proxy and cilium, and it won&rsquo;t take too long to
realize that the order of <code>CILIUM_FORWARD</code> and <code>KUBE-FORWARD</code> relies on which
component starts first initially. In a typical case, if cilium starts later than
kube-proxy, <code>CILIUM_FORWARD</code> is going to be prepended and thus takes higher
precedence. However if kube-proxy starts after cilium, then <code>KUBE-FORWARD</code> will
take precedence, and in this case, it breaks pod connectivity.</p>
<h2 id="why-ctstate-is-invalid">Why ctstate is INVALID</h2>
<p>iptables tracks connection states, but if only part of traffic goes through
iptables, then it won&rsquo;t recognize the connection states correctly. In this case
here, we have <code>bpf.masquerade=true</code> configured in cilium. It basically means
cilium actually does snat via bpf directly (in contrast to doing it in
iptables). With that said, when iptables sees there is an ACK without knowing
there was a SYN before, it is considered as INVALID.</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
        <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "zhouhaibing089" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://blog.zhouhaibing.com/" >
    &copy;  Blog 2023 
  </a>
    <div>














</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
